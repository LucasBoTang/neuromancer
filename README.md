# NeuroMANCER
## Neural Modules with Adaptive Nonlinear Constraints and 	Efficient Regularizations
![UML diagram](figs/class_diagram.png)

## Setup

##### Clone and install neuromancer, linear maps, and emulator packages
```console
user@machine:~$ mkdir ecosystem; cd ecosystem
user@machine:~$ git clone https://stash.pnnl.gov/scm/deepmpc/neuromancer.git
user@machine:~$ git clone https://stash.pnnl.gov/scm/deepmpc/psl.git
user@machine:~$ git clone https://stash.pnnl.gov/scm/deepmpc/slim.git

# Resulting file structure:
    ecosystem/
        neuromancer/
        psl/
        slim/
```

##### Create the environment via .yml (Linux)

```console
user@machine:~$ conda env create -f env.yml
(neuromancer) user@machine:~$ source activate neuromancer
```

##### If .yml env creation fails create the environment manually

```console
user@machine:~$ conda config --add channels conda-forge pytorch
user@machine:~$ conda create -n neuromancer python=3.7
user@machine:~$ source activate neuromancer
(neuromancer) user@machine:~$ conda install pytorch torchvision cudatoolkit=10.2 -c pytorch
(neuromancer) user@machine:~$ conda install scipy pandas matplotlib control pyts numba scikit-learn mlflow dill
(neuromancer) user@machine:~$ conda install -c powerai gym
```

##### install neuromancer ecosystem 

```console
(neuromancer) user@machine:~$ cd psl
(neuromancer) user@machine:~$ python setup.py develop
(neuromancer) user@machine:~$ cd ../slim
(neuromancer) user@machine:~$ python setup.py develop
(neuromancer) user@machine:~$ cd ../neuromancer
(neuromancer) user@machine:~$ python setup.py develop
```

### TODO
    [1] cleanup train_scripts folder
        how to solve problem with exploding number of training scripts?
        identify changes and moving parts
        identify strategy for preventing replicating code in the future
        suggestion new folders:    
            template_scripts - demonstrating full functionality
            example_scripts - starter scripts with concrete examples, published experiments
            dev_scripts - development scripts for publications
        two types of APIs: 
            high level API - user oriented
            low level API - advanced user and developer oriented
    
    [2] datasets
        move datasets to psl
        refactor datasets.py - get rid of unnecessary dependencies
        other normalizations: [-1, 1], normal distribution - part of our hyperparametrization choice
    
    [3] create new analysis file
        post hoc analysis of neural nets
        decouple eigenvalue analysis from visuals in trainer
        add eigenvalue analysis for all weights, neural blocks, and all activation types     

    [4] trainer
        keep current trainer
        set random seeds for reproducibility
        add profiling
        
    [5] logger 
        add save weights option during training for running offline visuals and analysis
        
    [6] dynamics, estimator, policies
        no immediate actions
        reduce code by generalizing model classes and helper functions
    
    [7] documentation
        autogenerate docs via doc strings
        python package style format with latex syntax
    
    
### Older TODOs
datasets category
    [ ] In datasets add data_transforms method to act on dataset.data to generate: finite difference sequences via np.diff, nonlinear expansions, spectral decompositions
    [ ] unify batching/unbatching via single function in datasets.py?
    [ ] finish batch_data_exp_id for datasets generated via multiple experiment runs: batch based on exp_idx and nsteps
    [ ] Mini-batching
visuals category
    [ ] update plot_matrix method in VisualizerOpen(Visualizer) - currently supports only linear maps with effective_W
    [ ] Visualizer for Multi-parametric programs
    [ ] Visualize learnable loss function evolution
    [ ] stream plots for phase spaces of ODEs
problem modeling and training script functions category
    [ ] move freeze_weight, unfreeze_weight, and share_weights into problem.py?
    [ ] add output_keys attribute to components 
    [ ] add input_keys and output_keys attributes to overall model generated by Problem()
    [ ] Generalize sliding window between 1 and nsteps
trainer category
    [ ] Learn-rate scheduling
    [ ] WandB logger
blocks, dynamics, policies, estimators category    
    [ ] Re-implement RNN state preservation for open loop simulation
    [ ] full trajectory estimators: This will entail only taking the first N-steps for all the non-static inputs
    [ ] Pytorch Extended Kalman Filter: 
            https://filterpy.readthedocs.io/en/latest/_modules/filterpy/kalman/EKF.html
    [ ] Implement LQR policy, similar structure to Linear Kalman Filter: 
            Scipy reference https://nbviewer.jupyter.org/url/argmin.net/code/little_LQR_demo.ipynb
dissemination and documentation category
    [ ] Doc strings
    [ ] Sphinx docs
    [ ] Package distribution via conda or pypi
    [ ] Look at this testing software to for automatic wider test coverage: 
            https://hypothesis.readthedocs.io/en/latest/